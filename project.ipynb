{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Conservation Bagging Support Vector Classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Introduction\n",
    "This project explores an idea derived from *Conservation Random Forests*, written by Moshe Sipper and Jason H. Moore. In their paper, Sipper and Moore use cultivation methods with decision trees and show that a significant improvement can be attained by using models that are already in possession. This project extends the work done in *Conservation Random Forests* by evaluating the utilized cultivation methods when decision trees are replaced with support vector classifiers (SVCs)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Methods\n",
    "Similar to the methods used in *Conservation Random Forests*, 3 methods are used to produce final ensembles: factory, super-ensemble, and lexiworkshop.\n",
    "\n",
    "### 1. Factory\n",
    "The factory method is similar to the jungle method used in *Conservation Random Forests*. With the factory method, multiple bagging classifiers that use SVCs as base estimators are trained. Then, all SVCs in each bagging classifier are added to a collection called a factory. The name \"factory\" arises from the fact that a factory has many machines; in this case, the machines are support vector machines. The factory performs class predictions through majority voting, where each SVC votes for a single class.\n",
    "\n",
    "### 2. Super-ensemble\n",
    "The super-ensemble method is similar to the super-ensemble method used in *Conservation Random Forests*. With the super-ensemble method, each bagging classifier is added to a collection called a super-ensemble. The name \"super-ensemble\" comes from the fact that a super-ensemble collection is an ensemble of ensembles. Prediction for the super-ensemble is also made through majority voting, where each bagging classifier votes for a single class.\n",
    "\n",
    "### 3. Lexiworkshop\n",
    "The lexiworshop method is similar to the lexigarden method used in *Conservation Random Forests*. The lexiworkshop method receives a factory (a collection of SVCs) and returns a workshop (a subset of the collection of SVCs) of a specified size. The SVCs in the workshop are selected through lexicase selection. The name \"workshop\" is used here because a workshop contains fewer machines relative to a factory. Like the previous methods, the lexiworkshop method performs class predictions via majority voting, where each SVC in the workshop votes for a single class.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Datasets\n",
    "\n",
    "The datasets used in this project are a subset of those used in *Conservation Random Forest*. Datasets were selected with the intention of creating a diverse collection of datasets. Here, our datasets come from 4 different sources: \n",
    "\n",
    "### 1. Easy\n",
    "This is Scikit-learn's \"easy\" collection of datasets where high performance is expected. These datasets are loaded via Scikit-learn's API. The datasets used from this source are:\n",
    "- [iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)\n",
    "- [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)\n",
    "- [breast cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "- [digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits)\n",
    "\n",
    "### 2. Clf\n",
    "This source refers to datasets created using Scikit-learn's [`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification) function that \"initially creates clusters of points normally distributed (std=1) about vertices of an `n_informative`-dimensional hypercube with sides of length 2*`class_sep` and assigns an equal number of clusters to each class.\" This project creates three different datasets using the following function calls:\n",
    "- `make_classification(n_samples=500, n_features=400, n_informative=200, n_classes=4, random_state=0)`\n",
    "- `make_classification(n_samples=1000, n_features=100, n_informative=90, n_classes=2, random_state=0)`\n",
    "- `make_classification(n_samples=1000, n_features=300, n_informative=200, n_classes=4, random_state=0)`\n",
    "\n",
    "### 3. OpenML\n",
    "OpenML is a repository of over 21,000 datasets. The datasets selected from OpenML are listed below and saved in `datasets/openML/` as `.csv` files:\n",
    "- [teachingAssistant](https://www.openml.org/d/1115)\n",
    "- [monk-problems-2](https://www.openml.org/d/334)\n",
    "- [one-hundred-plants-margin](https://www.openml.org/d/1491)\n",
    "\n",
    "### 4. PMLB\n",
    "The [Penn Machine Learning Benchmark](https://epistasislab.github.io/pmlb/) repository is a public benchmark resource to help identify the strengths and weaknesses of different machine learning techniques. This project accesses these datasets using the `pmlb` Python Package Index (PyPI). The PMLB datasets used in this project are listed below and cached in `datasets/PMLB/`:\n",
    "- [allrep](https://epistasislab.github.io/pmlb/profile/allrep.html)\n",
    "- [biomed](https://epistasislab.github.io/pmlb/profile/biomed.html)\n",
    "- [car_evaluation](https://epistasislab.github.io/pmlb/profile/car_evaluation.html)\n",
    "- [cloud](https://epistasislab.github.io/pmlb/profile/cloud.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Experiments\n",
    "\n",
    "### Setup\n",
    "The experimental setup for this project is very similar to that of *Conservation Random Forests*; however, the experiments here are scaled back relative to those conducted in the paper. \n",
    "\n",
    "The project's experiments use Scikit-learn's `SVC` (with default parameters) and `BaggingClassifier` objects. 10 replicate runs are conducted for each of the 14 datasets above. For each replicate run, 5 folds are created for 5-fold cross-validation. For each fold, the dataset is split into a training set of 4 folds and the left-out test fold. 10 runs are conducted for each fold. Each run includes fitting a 100-SVC bagging classifier to the training set and testing the fitted bagging classifier on the test set. In addition, all SVCs are saved into a factory, and all bagging classifiers are saved into a super-ensemble. Both the factory and super-ensemble are tested on the test set. The factory serves to produce workshops of sizes 100, 300, and 500, which are tested as well. \n",
    "\n",
    "For each of the 10 replicate runs on a dataset, the mean accuracy score across all 5 folds are saved for each method (factory, super-ensemble, lexiworkshop of size 100, lexiworkshop of size 300, and lexiworkshop of size 500) as a `.csv` file in `results/`.\n",
    "\n",
    "### Code\n",
    "#### `experiment.py`\n",
    "This file contains all the functions for each experiment. The main algorithm for the experimental setup is detailed in `experiment()`. The lexiworkshop method is detailed in `lexiworkshop()`.\n",
    "\n",
    "#### `drivers.py`\n",
    "This file contains driver functions that call `experiment()` on the datasets for each source. For example, `openml_driver()` runs experiments on all the datasets from the OpenML. Each driver function is called in this `.ipynb` file and run on Google Colab. The following cells run each driver function; however, there is no need to run these cells again since the results of the experiments have already been saved in `results/`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run this cell for google colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')\n",
    "# %cd /content/gdrive/MyDrive/COSC-247/Final\\ Project/conservation-bagging-svcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pmlb in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (1.0.1.post3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from pmlb) (1.1.1)\n",
      "Requirement already satisfied: requests>=2.24.0 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from pmlb) (2.24.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from pmlb) (5.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.0.5->pmlb) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.0.5->pmlb) (1.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.0.5->pmlb) (2.8.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.24.0->pmlb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.24.0->pmlb) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.24.0->pmlb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.24.0->pmlb) (1.25.10)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alexanderlee/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.5->pmlb) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install the pmlb PyPI using pip\n",
    "%pip install pmlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import driver functions from drivers.py\n",
    "from drivers import easy_driver, clf_driver, openml_driver, pmlb_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run this cell to run all experiments\n",
    "# however, there is no need to because the results have already been saved in results/\n",
    "\n",
    "# easy_driver()\n",
    "# clf_driver()\n",
    "# openml_driver()\n",
    "# pmlb_driver()"
   ]
  },
  {
   "source": [
    "## Results\n",
    "\n",
    "`transform_results.py` contains a function called `get_combined_results()` that compiles all the results from each experiment to display as a `pandas.DataFrame`. Each row of the `DataFrame` presents the results of running `experiment()` (10 replicate runs) on a single dataset. Each column of the `DataFrame` is detailed below:\n",
    "- `source`: The source of the dataset.\n",
    "- `dataset`: The name of the dataset.\n",
    "- `bag_svc`: The mean accuracy score of bagging classifiers across all replicate runs.\n",
    "- `factory`: The mean accuracy score of the factory method across all replicate runs.\n",
    "- `super_ensemble`: The mean accuracy score of the super-ensemble method across all replicate runs.\n",
    "- `workshop_100`: The mean accuracy score of the lexiworkshop method of size 100 across all replicate runs.\n",
    "- `workshop_300`: The mean accuracy score of the lexiworkshop method of size 300 across all replicate runs.\n",
    "- `workshop_500`: The mean accuracy score of the lexiworkshop method of size 500 across all replicate runs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    source                    dataset  bag_svc  factory  super_ensemble  \\\n",
       "0     Easy                       iris     96.1     96.1            96.1   \n",
       "1     Easy                       wine     98.4     98.4            98.4   \n",
       "2     Easy              breast cancer     97.7     97.7            97.6   \n",
       "3     Easy                     digits     98.1     98.1            98.1   \n",
       "4      Clf              500_400_200_4     43.7     43.6            43.7   \n",
       "5      Clf              1000_100_90_2     89.6     89.6            89.5   \n",
       "6      Clf             1000_300_200_4     58.1     58.0            58.2   \n",
       "7   OpenML          teachingAssistant     57.7     58.4            58.2   \n",
       "8   OpenML            monk-problems-2     74.0     74.3            74.0   \n",
       "9   OpenML  one-hundred-plants-margin     79.8     79.9            79.9   \n",
       "10    PMLB                      cloud     26.1     25.7            25.6   \n",
       "11    PMLB                     biomed     89.3     89.4            89.4   \n",
       "12    PMLB             car_evaluation     97.3     97.3            97.3   \n",
       "13    PMLB                     allrep     96.7     96.7            96.7   \n",
       "\n",
       "    workshop_100  workshop_300  workshop_500  \n",
       "0           99.6          99.6          99.6  \n",
       "1          100.0         100.0         100.0  \n",
       "2           99.1          99.1          99.1  \n",
       "3           98.8          98.8          98.8  \n",
       "4           48.2          48.3          48.4  \n",
       "5           92.0          92.1          92.0  \n",
       "6           60.3          60.3          60.4  \n",
       "7           69.1          68.7          69.0  \n",
       "8           80.8          81.2          81.2  \n",
       "9           81.9          81.9          82.0  \n",
       "10          46.8          47.1          46.8  \n",
       "11          95.0          95.0          95.0  \n",
       "12          99.2          99.3          99.3  \n",
       "13          97.0          97.1          97.1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>dataset</th>\n      <th>bag_svc</th>\n      <th>factory</th>\n      <th>super_ensemble</th>\n      <th>workshop_100</th>\n      <th>workshop_300</th>\n      <th>workshop_500</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Easy</td>\n      <td>iris</td>\n      <td>96.1</td>\n      <td>96.1</td>\n      <td>96.1</td>\n      <td>99.6</td>\n      <td>99.6</td>\n      <td>99.6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Easy</td>\n      <td>wine</td>\n      <td>98.4</td>\n      <td>98.4</td>\n      <td>98.4</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Easy</td>\n      <td>breast cancer</td>\n      <td>97.7</td>\n      <td>97.7</td>\n      <td>97.6</td>\n      <td>99.1</td>\n      <td>99.1</td>\n      <td>99.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Easy</td>\n      <td>digits</td>\n      <td>98.1</td>\n      <td>98.1</td>\n      <td>98.1</td>\n      <td>98.8</td>\n      <td>98.8</td>\n      <td>98.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clf</td>\n      <td>500_400_200_4</td>\n      <td>43.7</td>\n      <td>43.6</td>\n      <td>43.7</td>\n      <td>48.2</td>\n      <td>48.3</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Clf</td>\n      <td>1000_100_90_2</td>\n      <td>89.6</td>\n      <td>89.6</td>\n      <td>89.5</td>\n      <td>92.0</td>\n      <td>92.1</td>\n      <td>92.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Clf</td>\n      <td>1000_300_200_4</td>\n      <td>58.1</td>\n      <td>58.0</td>\n      <td>58.2</td>\n      <td>60.3</td>\n      <td>60.3</td>\n      <td>60.4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>OpenML</td>\n      <td>teachingAssistant</td>\n      <td>57.7</td>\n      <td>58.4</td>\n      <td>58.2</td>\n      <td>69.1</td>\n      <td>68.7</td>\n      <td>69.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>OpenML</td>\n      <td>monk-problems-2</td>\n      <td>74.0</td>\n      <td>74.3</td>\n      <td>74.0</td>\n      <td>80.8</td>\n      <td>81.2</td>\n      <td>81.2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>OpenML</td>\n      <td>one-hundred-plants-margin</td>\n      <td>79.8</td>\n      <td>79.9</td>\n      <td>79.9</td>\n      <td>81.9</td>\n      <td>81.9</td>\n      <td>82.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>PMLB</td>\n      <td>cloud</td>\n      <td>26.1</td>\n      <td>25.7</td>\n      <td>25.6</td>\n      <td>46.8</td>\n      <td>47.1</td>\n      <td>46.8</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>PMLB</td>\n      <td>biomed</td>\n      <td>89.3</td>\n      <td>89.4</td>\n      <td>89.4</td>\n      <td>95.0</td>\n      <td>95.0</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>PMLB</td>\n      <td>car_evaluation</td>\n      <td>97.3</td>\n      <td>97.3</td>\n      <td>97.3</td>\n      <td>99.2</td>\n      <td>99.3</td>\n      <td>99.3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>PMLB</td>\n      <td>allrep</td>\n      <td>96.7</td>\n      <td>96.7</td>\n      <td>96.7</td>\n      <td>97.0</td>\n      <td>97.1</td>\n      <td>97.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from transform_results import get_combined_results\n",
    "\n",
    "get_combined_results()"
   ]
  },
  {
   "source": [
    "## Concluding Remarks\n",
    "\n",
    "As can be seen in the above `DataFrame`, the results of this project differ from those found in *Conservation Random Forests*. In *Conservation Random Forests*, all \"methods used to produce final ensembles proved efficacious to some degree or other,\" with lexigarden methods taking the lead. However, in this project, only the lexiworkshop methods had better accuracy scores than those of standard bagging classifiers. In this case, while it cannot be concluded that the factory and super-ensemble methods were effective in increasing accuracy, it is evident that the lexiworkshop method was effective in doing so. This result further exemplifies the ability for lexicase selection to improve the accuracy of cultivation methods. \n",
    "\n",
    "In regards to future work, more exploration could be done to understand why the factory and super-ensemble methods did not have better accuracy scores relative to standard bagging classifiers in this project. Additionally, other base classifiers such as logistic regressors could be used to explore the generalizability of the cultivation methods across different models. Similarly, as mentioned in *Conservation Random Forests*, further research on applying these methods to regression and clustering tasks instead of classification tasks could prove to be beneficial as well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}